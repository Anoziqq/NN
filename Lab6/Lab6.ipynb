{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PG_5NatILDLo",
        "lnBqJE2iLZDP",
        "QSXsJ-qoLfd-",
        "lu-pKg8nMS1X"
      ],
      "authorship_tag": "ABX9TyPVhqKDHW+cvvM2hCX0BnEO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anoziqq/NN/blob/main/Lab6/Lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Лабораторна робота 6\n",
        "#З дисципліни \"Нейронні мережі\"\n",
        "##Виконав студент:\n",
        "###групи АнД-31\n",
        "###Лаврій Руслан"
      ],
      "metadata": {
        "id": "cGBHqKOULCHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Завдання\n",
        "## 1. Виконати вирішення задачі класифікації для 3 класів з набору даних food101 з використанням різних моделей нейронних мереж:\n",
        "## 1.1 CNN модель з лабораторної роботи 4\n",
        "## 1.2 Resnet модель\n",
        "## 1.3 Efficientnet модель (моделі 1.1-1.3 з використанням оптимізатора Adam)\n",
        "## 1.4 (1.5) Моделі 1.2,1.3 з використанням оптимізатора SGD.\n",
        "## 1.6 (1.7) Моделі 1.2,1.3 отримані за допомогою tf.keras.applications та треновані з використанням fine-tuning (останні 10 шарів)\n",
        "## 2. Індекси класів визначити індивідуально за залежностями: i1=n-1,i2=n+29,i3=n+59 (де і1,і2,і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних, n - номер за списком групи.\n",
        "## 3. Порівняти результати моделювання із використанням TensorBoard\n",
        "## 4. Графік(и) порівняння результатів завантажити у форматі .svg та вставити у підсумковий файл поряд із та відповідними висновками\n",
        "## i1=5, i2=35, i3=65\n"
      ],
      "metadata": {
        "id": "PG_5NatILDLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3VOX3lF1LBQn"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "file = tarfile.open(\"food-101.tar.gz\")\n",
        "file.extractall()\n",
        "file.close()\n",
        "!ls food-101"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb0Li8OLMJ7u",
        "outputId": "c50619d6-9b90-4df3-e310-8b2e347efd5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-06 13:27:58--  http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz [following]\n",
            "--2022-06-06 13:27:58--  https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4996278331 (4.7G) [application/x-gzip]\n",
            "Saving to: ‘food-101.tar.gz’\n",
            "\n",
            "food-101.tar.gz     100%[===================>]   4.65G  31.7MB/s    in 2m 57s  \n",
            "\n",
            "2022-06-06 13:30:56 (26.9 MB/s) - ‘food-101.tar.gz’ saved [4996278331/4996278331]\n",
            "\n",
            "images\tlicense_agreement.txt  meta  README.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Знаходження класів"
      ],
      "metadata": {
        "id": "lnBqJE2iLZDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('food-101/meta/classes.txt')\n",
        "line_numbers = [5, 35, 65] \n",
        "lines = []\n",
        "for i, line in enumerate(file):\n",
        "  if i in line_numbers:\n",
        "    lines.append(line.strip())\n",
        "print(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWLTE2laMWDf",
        "outputId": "ad6f549d-967b-42aa-dcc2-2bee99f23764"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['beet_salad', 'escargots', 'mussels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Створення папок і копіювання фото"
      ],
      "metadata": {
        "id": "QSXsJ-qoLfd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir food-101/test\n",
        "!mkdir food-101/train\n",
        "!mkdir food-101/test/beet_salad\n",
        "!mkdir food-101/test/escargots\n",
        "!mkdir food-101/test/mussels\n",
        "!mkdir food-101/train/beet_salad\n",
        "!mkdir food-101/train/escargots\n",
        "!mkdir food-101/train/mussels\n",
        "\n",
        "file = open('food-101/meta/train.txt')\n",
        "for i in file:\n",
        "  dir = i.split(\"/\")\n",
        "  if (dir[0] == 'beet_salad'):\n",
        "    shutil.copy('food-101/images/'+i.replace('\\n','') +'.jpg', 'food-101/train/beet_salad')\n",
        "  elif(dir[0] == 'escargots'):\n",
        "    shutil.copy('food-101/images/'+i.replace('\\n','') +'.jpg', 'food-101/train/escargots')\n",
        "  elif(dir[0] == 'mussels'):\n",
        "    shutil.copy('food-101/images/'+i.replace('\\n','') +'.jpg', 'food-101/train/mussels')\n",
        "\n",
        "file = open('food-101/meta/test.txt')\n",
        "for i in file:\n",
        "  dir = i.split(\"/\")\n",
        "  if (dir[0] == 'beet_salad'):\n",
        "    shutil.copy('food-101/images/'+i.replace('\\n','') +'.jpg', 'food-101/test/beet_salad')\n",
        "  elif(dir[0] == 'escargots'):\n",
        "    shutil.copy('food-101/images/'+i.replace('\\n','') +'.jpg', 'food-101/test/escargots')\n",
        "  elif(dir[0] == 'mussels'):\n",
        "    shutil.copy('food-101/images/'+i.replace('\\n','') +'.jpg', 'food-101/test/mussels')\n",
        "!ls food-101/test\n",
        "test_dir = 'food-101/test'\n",
        "train_dir = 'food-101/train'\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muZcc5DPMV0I",
        "outputId": "944b4851-71a8-4a26-882d-4a4d516c9b4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beet_salad  escargots  mussels\n",
            "['beet_salad' 'escargots' 'mussels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Перетворення зображень та покращення"
      ],
      "metadata": {
        "id": "lu-pKg8nMS1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical')\n",
        "\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')\n",
        "\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=20,\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                  target_size=(224, 224),\n",
        "                                                                  batch_size=32,\n",
        "                                                                  class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v20bFvrmMVO_",
        "outputId": "74645a7c-ff27-4911-e28a-d81743cf4a98"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2250 images belonging to 3 classes.\n",
            "Found 750 images belonging to 3 classes.\n",
            "Found 2250 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "HFkuykfxMVfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential([\n",
        "  Conv2D(32, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Conv2D(64, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='logs/cnn', histogram_freq=1)\n",
        "\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_1 = model_1.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks = [tb_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfXTwX1gN3ju",
        "outputId": "79250cdc-aed4-42ba-8904-a5de65e56b52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "71/71 [==============================] - 50s 528ms/step - loss: 1.1738 - accuracy: 0.3711 - val_loss: 1.0283 - val_accuracy: 0.5013\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 35s 498ms/step - loss: 1.0260 - accuracy: 0.4587 - val_loss: 0.9578 - val_accuracy: 0.5240\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 35s 494ms/step - loss: 1.0028 - accuracy: 0.5000 - val_loss: 0.8773 - val_accuracy: 0.6173\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 37s 525ms/step - loss: 0.9660 - accuracy: 0.5658 - val_loss: 0.8133 - val_accuracy: 0.6800\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 35s 498ms/step - loss: 0.9268 - accuracy: 0.6084 - val_loss: 0.8871 - val_accuracy: 0.6627\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 35s 495ms/step - loss: 0.9350 - accuracy: 0.5773 - val_loss: 0.9217 - val_accuracy: 0.5720\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 36s 504ms/step - loss: 0.9330 - accuracy: 0.5684 - val_loss: 0.7774 - val_accuracy: 0.6493\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 35s 494ms/step - loss: 0.8842 - accuracy: 0.6391 - val_loss: 0.7993 - val_accuracy: 0.6813\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 35s 496ms/step - loss: 0.8379 - accuracy: 0.6618 - val_loss: 0.7298 - val_accuracy: 0.7267\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 35s 494ms/step - loss: 0.8481 - accuracy: 0.6596 - val_loss: 0.7088 - val_accuracy: 0.7387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet ADAM"
      ],
      "metadata": {
        "id": "FaklHXyJNay-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/5\",\n",
        "                   trainable=False),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model_2.build([None, 224, 224, 3])\n",
        "\n",
        "tb_callback_2 = tf.keras.callbacks.TensorBoard(log_dir='logs/resnet(adam)notunnig', histogram_freq=1)\n",
        "\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_2 = model_2.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks=[tb_callback_2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8swT3dxN391",
        "outputId": "e893c918-8167-438b-ea3b-5ae106432212"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "71/71 [==============================] - 56s 678ms/step - loss: 0.5805 - accuracy: 0.7720 - val_loss: 0.2696 - val_accuracy: 0.9120\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 46s 643ms/step - loss: 0.3298 - accuracy: 0.8787 - val_loss: 0.2225 - val_accuracy: 0.9253\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 44s 626ms/step - loss: 0.2670 - accuracy: 0.9049 - val_loss: 0.1955 - val_accuracy: 0.9347\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 45s 637ms/step - loss: 0.2418 - accuracy: 0.9089 - val_loss: 0.1865 - val_accuracy: 0.9333\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 44s 624ms/step - loss: 0.2148 - accuracy: 0.9249 - val_loss: 0.1765 - val_accuracy: 0.9387\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 44s 625ms/step - loss: 0.2085 - accuracy: 0.9240 - val_loss: 0.1657 - val_accuracy: 0.9453\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 44s 628ms/step - loss: 0.1911 - accuracy: 0.9316 - val_loss: 0.1562 - val_accuracy: 0.9453\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 45s 631ms/step - loss: 0.1740 - accuracy: 0.9373 - val_loss: 0.1581 - val_accuracy: 0.9467\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 45s 631ms/step - loss: 0.1886 - accuracy: 0.9302 - val_loss: 0.1594 - val_accuracy: 0.9493\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 45s 630ms/step - loss: 0.1759 - accuracy: 0.9360 - val_loss: 0.1640 - val_accuracy: 0.9480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet ADAM"
      ],
      "metadata": {
        "id": "EEs6zaMxNo-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
        "                   trainable=False),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model_3.build([None, 224, 224, 3])\n",
        "\n",
        "tb_callback_3 = tf.keras.callbacks.TensorBoard(log_dir='logs/effnet(adam)notunning', histogram_freq=1)\n",
        "\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_3 = model_3.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks = [tb_callback_3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrmWY2jmN4Vk",
        "outputId": "4c4b3cf1-d8c8-461a-eca2-7681d0953715"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "71/71 [==============================] - 48s 540ms/step - loss: 0.5152 - accuracy: 0.8240 - val_loss: 0.2445 - val_accuracy: 0.9360\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 37s 528ms/step - loss: 0.2677 - accuracy: 0.9160 - val_loss: 0.1951 - val_accuracy: 0.9467\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 37s 520ms/step - loss: 0.2227 - accuracy: 0.9262 - val_loss: 0.1723 - val_accuracy: 0.9480\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 37s 524ms/step - loss: 0.2009 - accuracy: 0.9338 - val_loss: 0.1568 - val_accuracy: 0.9520\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 37s 518ms/step - loss: 0.1882 - accuracy: 0.9369 - val_loss: 0.1605 - val_accuracy: 0.9507\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 38s 536ms/step - loss: 0.1715 - accuracy: 0.9453 - val_loss: 0.1475 - val_accuracy: 0.9480\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 37s 517ms/step - loss: 0.1595 - accuracy: 0.9493 - val_loss: 0.1472 - val_accuracy: 0.9507\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 38s 534ms/step - loss: 0.1526 - accuracy: 0.9493 - val_loss: 0.1457 - val_accuracy: 0.9507\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 37s 524ms/step - loss: 0.1445 - accuracy: 0.9564 - val_loss: 0.1361 - val_accuracy: 0.9573\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 37s 515ms/step - loss: 0.1352 - accuracy: 0.9564 - val_loss: 0.1362 - val_accuracy: 0.9547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet SGD"
      ],
      "metadata": {
        "id": "anoW1NT4Nwnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/5\",\n",
        "                   trainable=False),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model_4.build([None, 224, 224, 3])\n",
        "\n",
        "tb_callback_4 = tf.keras.callbacks.TensorBoard(log_dir='logs/resnet(sgd)notunnig', histogram_freq=1)\n",
        "\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_4 = model_4.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks=[tb_callback_4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTtt9AeqN4qM",
        "outputId": "5babb619-9482-421e-cece-954318730ef6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "71/71 [==============================] - 53s 655ms/step - loss: 0.5156 - accuracy: 0.8076 - val_loss: 0.2657 - val_accuracy: 0.9107\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 46s 646ms/step - loss: 0.3244 - accuracy: 0.8796 - val_loss: 0.2273 - val_accuracy: 0.9280\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 46s 646ms/step - loss: 0.2938 - accuracy: 0.8964 - val_loss: 0.2098 - val_accuracy: 0.9227\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 46s 651ms/step - loss: 0.2856 - accuracy: 0.9009 - val_loss: 0.2104 - val_accuracy: 0.9280\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 46s 643ms/step - loss: 0.2523 - accuracy: 0.9160 - val_loss: 0.1937 - val_accuracy: 0.9307\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 47s 658ms/step - loss: 0.2352 - accuracy: 0.9138 - val_loss: 0.1946 - val_accuracy: 0.9253\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 46s 647ms/step - loss: 0.2210 - accuracy: 0.9196 - val_loss: 0.1957 - val_accuracy: 0.9280\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 46s 650ms/step - loss: 0.2166 - accuracy: 0.9107 - val_loss: 0.1884 - val_accuracy: 0.9413\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 46s 647ms/step - loss: 0.2147 - accuracy: 0.9276 - val_loss: 0.1762 - val_accuracy: 0.9360\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 46s 643ms/step - loss: 0.2083 - accuracy: 0.9280 - val_loss: 0.2039 - val_accuracy: 0.9320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet SGD"
      ],
      "metadata": {
        "id": "PqbF6mE3N0he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
        "                   trainable=False),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model_5.build([None, 224, 224, 3])\n",
        "\n",
        "tb_callback_5 = tf.keras.callbacks.TensorBoard(log_dir='logs/effnet(sgd)notunning', histogram_freq=1)\n",
        "\n",
        "model_5.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_5 = model_5.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks = [tb_callback_5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHYmarmN5BF",
        "outputId": "a9dff8fb-88c1-4a71-fc20-7d6482f4ddb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "71/71 [==============================] - 46s 531ms/step - loss: 0.6909 - accuracy: 0.7524 - val_loss: 0.4224 - val_accuracy: 0.8987\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 37s 521ms/step - loss: 0.4058 - accuracy: 0.8844 - val_loss: 0.3069 - val_accuracy: 0.9227\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 39s 550ms/step - loss: 0.3351 - accuracy: 0.8978 - val_loss: 0.2606 - val_accuracy: 0.9347\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 37s 516ms/step - loss: 0.2921 - accuracy: 0.9111 - val_loss: 0.2355 - val_accuracy: 0.9427\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 37s 517ms/step - loss: 0.2791 - accuracy: 0.9102 - val_loss: 0.2171 - val_accuracy: 0.9400\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 37s 516ms/step - loss: 0.2547 - accuracy: 0.9236 - val_loss: 0.2082 - val_accuracy: 0.9453\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 37s 517ms/step - loss: 0.2475 - accuracy: 0.9244 - val_loss: 0.1976 - val_accuracy: 0.9453\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 38s 538ms/step - loss: 0.2408 - accuracy: 0.9222 - val_loss: 0.1918 - val_accuracy: 0.9467\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 37s 518ms/step - loss: 0.2324 - accuracy: 0.9280 - val_loss: 0.1867 - val_accuracy: 0.9493\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 37s 522ms/step - loss: 0.2257 - accuracy: 0.9360 - val_loss: 0.1834 - val_accuracy: 0.9440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Висновок. Як можна замітити, найточнішим методом виявився EfficientNet ADAM а найгіршим CNN"
      ],
      "metadata": {
        "id": "0SNKqn7CW4Zf"
      }
    }
  ]
}